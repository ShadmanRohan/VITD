{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "159ff494-4c9f-4163-8227-d086ed820a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from normalizer import normalize\n",
    "from transformers.modeling_outputs import TokenClassifierOutput, SequenceClassifierOutput\n",
    "from transformers import AutoModelForSequenceClassification, AutoModel, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f2e6ee-b71a-4cca-a052-ba53f2cc61c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/rohan/.cache/huggingface/datasets/csv/default-f391624b81d64ce9/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b964ec6345fa4a46855d4543f4a6dd60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "id2label = {\n",
    "    0 : 'Non-Violence',\n",
    "    1 : 'Passive Violence',\n",
    "    2 : 'Direct Violence'\n",
    "}\n",
    "\n",
    "label2id = {\n",
    "    'Non-Violence': 0,\n",
    "    'Passive Violence': 1,\n",
    "    'Direct Violence': 2\n",
    "}\n",
    "\n",
    "training_data = load_dataset(\"csv\", data_files={'train': ['./data_gen/train_paraphrased.csv'],'validation': ['./data_gen/validation_data.csv']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "933a517c-0e16-4505-b4fb-beed22b84510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score \n",
    "\n",
    "# Helper Functions\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1_weighted = f1_score(labels, preds, average=\"weighted\")\n",
    "    f1_macro = f1_score(labels, preds, average=\"macro\") \n",
    "    f1_micro = f1_score(labels, preds, average=\"micro\") \n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1_weighted\": f1_weighted, \"f1_macro\": f1_macro, \"f1_micro\": f1_micro}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f39afe97-586a-45a1-bb06-bbbc7db80885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at csebuetnlp/banglabert and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading cached processed dataset at /home/rohan/.cache/huggingface/datasets/csv/default-f391624b81d64ce9/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-e7aacc2f3aa59853.arrow\n",
      "Loading cached processed dataset at /home/rohan/.cache/huggingface/datasets/csv/default-f391624b81d64ce9/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-553d781adccae55a.arrow\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "num_labels = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model_ckpt = \"./csebuetnlp/banglabert-sentiment-analysis/checkpoint-4000/\"\n",
    "model_ckpt = \"csebuetnlp/banglabert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt, model_max_length=256) # local_files_only=True\n",
    "\n",
    "model = (AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels, id2label=id2label, label2id=label2id).to(device)) # local_files_only=True\n",
    "training_data_encoded = training_data.map(tokenize, batched=True, batch_size=64)\n",
    "\n",
    "#model = freeze_electra_layers(model, num_layers_to_freeze=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c358f9e-626f-4098-8912-7664d86ca394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12df675a-2db9-4c62-8d5c-589976d24287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments \n",
    "batch_size = 32\n",
    "logging_steps = len(training_data_encoded[\"train\"]) // batch_size \n",
    "model_name = f\"{model_ckpt}-sentiment-analysis\"\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                  num_train_epochs=10, \n",
    "                                  #num_training_steps=100, \n",
    "                                  learning_rate=2e-5, #2e-4\n",
    "                                  #warmup_steps=10000,\n",
    "                                  per_device_train_batch_size=batch_size, \n",
    "                                  per_device_eval_batch_size=batch_size, \n",
    "                                  eval_steps=100,\n",
    "                                  logging_steps = 100,\n",
    "                                  weight_decay=0.01, #1e-3, 1e-5\n",
    "                                  evaluation_strategy=\"steps\", \n",
    "                                  save_strategy=\"steps\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  #logging_steps=logging_steps,\n",
    "                                  save_steps = 100, \n",
    "                                  save_total_limit = 2,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  metric_for_best_model=\"f1_macro\",   #\"loss\",\n",
    "                                  greater_is_better=True, #False\n",
    "                                  optim='adamw_torch',\n",
    "                                  lr_scheduler_type= \"linear\", #cosine_with_restarts # cosine\n",
    "                                  log_level=\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fe774c4-a5fc-4394-9795-76b332fe3f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dd82027-2d54-470b-bb29-e9e738710b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#!sudo apt-get install git-lfs\n",
    "from transformers import Trainer\n",
    "\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Sample hyperparameters\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 2e-5, 2e-4, log=True)\n",
    "    num_train_epochs = trial.suggest_int(\"num_train_epochs\", 1, 5)\n",
    "    per_device_train_batch_size = trial.suggest_int(\"per_device_train_batch_size\", 32, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
    "\n",
    "    # Update training args with sampled hyperparameters\n",
    "    training_args.learning_rate = learning_rate\n",
    "    training_args.num_train_epochs = num_train_epochs\n",
    "    training_args.per_device_train_batch_size = per_device_train_batch_size\n",
    "    training_args.weight_decay = weight_decay\n",
    "\n",
    "    trainer = Trainer(model=model, \n",
    "                      args=training_args,\n",
    "                      compute_metrics=compute_metrics,\n",
    "                      train_dataset=training_data_encoded[\"train\"], \n",
    "                      eval_dataset=training_data_encoded[\"validation\"],\n",
    "                      data_collator=data_collator,\n",
    "                      tokenizer=tokenizer,\n",
    "                      #class_weights=class_weights \n",
    "                     )\n",
    "    \n",
    "    # Train and evaluate the model\n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    # You seem to want to optimize for \"f1_macro\". Return this metric\n",
    "    return eval_results[\"eval_f1_macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95c2438d-9ae9-401d-b0bf-ea8aab7891f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#study = optuna.create_study(direction=\"maximize\")  # Maximize f1_macro\n",
    "#study.optimize(objective, n_trials=15)  # for example, run for 50 trials\n",
    "\n",
    "# Print best hyperparameters\n",
    "#print(f\"Best trial:\\n  Value: {study.best_value}\\n  Params: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959aca07-fae3-4383-8606-8ef1919766b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Best trial:\\n  Value: {study.best_value}\\n  Params: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51ed652-48e1-432b-b632-34815a60aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Best trial:\\n  Value: {study.best_value}\\n  Params: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d37de693-08a4-4e46-a9f5-3db32a51f5ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e37fd9b-e494-4f02-8f3a-01f3bd27c5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_output = trainer.predict(training_data_encoded[\"validation\"])\n",
    "preds_output.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15db054-aef9-4418-b30d-e099bcc11595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix \n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "  cm = confusion_matrix(y_true, y_preds, normalize='pred') \n",
    "  fig, ax = plt.subplots(figsize=(6, 6))\n",
    "  disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "  disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False) \n",
    "  plt.title(\"Normalized confusion matrix: Validation\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfe1be3-db4d-4a36-9b8b-e5ec17046e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_preds = np.argmax(preds_output.predictions, axis=1)\n",
    "#labels = training_data_encoded[\"train\"].features[\"label\"].names\n",
    "labels = [0,1,2]\n",
    "y_valid = training_data_encoded[\"validation\"][\"label\"]\n",
    "\n",
    "plot_confusion_matrix(y_preds, y_valid, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265e3862-1061-412a-9524-b295916cdb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv('./data_gen/backtranslated_train.csv')\n",
    "t.label.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390620af-12db-4209-8705-c26ddda70255",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b862c-e868-408d-b372-09e457fbd553",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4186651-46f9-4781-ae85-907d6a9c475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    # Move to GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        for key in inputs:\n",
    "            inputs[key] = inputs[key].cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "    return predictions.item()  # Assuming one prediction per call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0726911-9078-40e9-a078-e59bcad53fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'] = test['text'].apply(lambda x: predict(x, model, tokenizer))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf439cb-c6ff-4ce4-8286-c0b61744e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract necessary columns for submission\n",
    "#submission = test[['id', 'label']]\n",
    "\n",
    "# Save the dataframe to a CSV file\n",
    "test.to_csv('./submissions/task.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589f1f07-ae32-4cb5-9423-4e436869c9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Text Classification Env",
   "language": "python",
   "name": "textclassification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
