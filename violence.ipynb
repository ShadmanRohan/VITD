{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from normalizer import normalize\n",
    "from transformers.modeling_outputs import TokenClassifierOutput, SequenceClassifierOutput\n",
    "from transformers import AutoModelForSequenceClassification, AutoModel, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train = pd.read_csv('data/train.csv')\n",
    "validation = pd.read_csv('data/dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>পাডা পুতার মাঝখানে পরে সাধারণ ২ মানুষের জিবন শ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>করোনার চাপে অনেক কিছু বন্ধ ও অনেক বিধি নিষেধ ক...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>সঠিক তদন্ত করতে হবে। বিচারের আওতায় আনতে হবে য...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>যে লোকটা মারা গেছে তার কি হবে তার দায়ভার কে ন...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>নিউ মার্কেট এবং গুলিস্থান মার্কেটের ব্যবসায়ীর...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>নাটক টা সুন্দর ভাবে সাজিয়েছে আরো কত কিছু দেখত...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>নোংরা দেশ আর নোংরা জাতি হচ্ছে ভারত এঁরা কি বুঝ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>জে ছেলে মারা গেছে ওর কি হবে</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>এরাই নৈরাজ্য সৃষ্টি করছে</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>ব্রাহ্মণবাড়িয়ার হত্যা হলে, হেডলাইনে ব্রাহ্মণবা...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1330 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     পাডা পুতার মাঝখানে পরে সাধারণ ২ মানুষের জিবন শ...      0\n",
       "1     করোনার চাপে অনেক কিছু বন্ধ ও অনেক বিধি নিষেধ ক...      0\n",
       "2     সঠিক তদন্ত করতে হবে। বিচারের আওতায় আনতে হবে য...      0\n",
       "3     যে লোকটা মারা গেছে তার কি হবে তার দায়ভার কে ন...      0\n",
       "4     নিউ মার্কেট এবং গুলিস্থান মার্কেটের ব্যবসায়ীর...      1\n",
       "...                                                 ...    ...\n",
       "1325  নাটক টা সুন্দর ভাবে সাজিয়েছে আরো কত কিছু দেখত...      1\n",
       "1326  নোংরা দেশ আর নোংরা জাতি হচ্ছে ভারত এঁরা কি বুঝ...      1\n",
       "1327                        জে ছেলে মারা গেছে ওর কি হবে      0\n",
       "1328                           এরাই নৈরাজ্য সৃষ্টি করছে      1\n",
       "1329  ব্রাহ্মণবাড়িয়ার হত্যা হলে, হেডলাইনে ব্রাহ্মণবা...      0\n",
       "\n",
       "[1330 rows x 2 columns]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train.rename(columns={\"label\": \"label_name\"}) # change headings\n",
    "#validation = validation.rename(columns={\"label\": \"label_name\"}) # change headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map labels\n",
    "\n",
    "id2label = {\n",
    "    0 : 'Non-Violence',\n",
    "    1 : 'Passive Violence',\n",
    "    2 : 'Direct Violence'\n",
    "}\n",
    "\n",
    "label2id = {\n",
    "    'Non-Violence': 0,\n",
    "    'Passive Violence': 1,\n",
    "    'Direct Violence': 2\n",
    "}\n",
    "\n",
    "#train['label'] = train['label_name'].map(label2id)\n",
    "#validation['label'] = validation['label_name'].map(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train.drop(columns=['id', 'label_name'], axis=1)\n",
    "#validation = validation.drop(['id', 'label_name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>পাডা পুতার মাঝখানে পরে সাধারণ ২ মানুষের জিবন শ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>করোনার চাপে অনেক কিছু বন্ধ ও অনেক বিধি নিষেধ ক...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>সঠিক তদন্ত করতে হবে। বিচারের আওতায় আনতে হবে য...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>যে লোকটা মারা গেছে তার কি হবে তার দায়ভার কে ন...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>নিউ মার্কেট এবং গুলিস্থান মার্কেটের ব্যবসায়ীর...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>নাটক টা সুন্দর ভাবে সাজিয়েছে আরো কত কিছু দেখত...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>নোংরা দেশ আর নোংরা জাতি হচ্ছে ভারত এঁরা কি বুঝ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>জে ছেলে মারা গেছে ওর কি হবে</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>এরাই নৈরাজ্য সৃষ্টি করছে</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>ব্রাহ্মণবাড়িয়ার হত্যা হলে, হেডলাইনে ব্রাহ্মণবা...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1330 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     পাডা পুতার মাঝখানে পরে সাধারণ ২ মানুষের জিবন শ...      0\n",
       "1     করোনার চাপে অনেক কিছু বন্ধ ও অনেক বিধি নিষেধ ক...      0\n",
       "2     সঠিক তদন্ত করতে হবে। বিচারের আওতায় আনতে হবে য...      0\n",
       "3     যে লোকটা মারা গেছে তার কি হবে তার দায়ভার কে ন...      0\n",
       "4     নিউ মার্কেট এবং গুলিস্থান মার্কেটের ব্যবসায়ীর...      1\n",
       "...                                                 ...    ...\n",
       "1325  নাটক টা সুন্দর ভাবে সাজিয়েছে আরো কত কিছু দেখত...      1\n",
       "1326  নোংরা দেশ আর নোংরা জাতি হচ্ছে ভারত এঁরা কি বুঝ...      1\n",
       "1327                        জে ছেলে মারা গেছে ওর কি হবে      0\n",
       "1328                           এরাই নৈরাজ্য সৃষ্টি করছে      1\n",
       "1329  ব্রাহ্মণবাড়িয়ার হত্যা হলে, হেডলাইনে ব্রাহ্মণবা...      0\n",
       "\n",
       "[1330 rows x 2 columns]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = pd.DataFrame(train['text'].map(lambda x: normalize(x)))\n",
    "validation['text'] = pd.DataFrame(validation['text'].map(lambda x: normalize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/rohan/.cache/huggingface/datasets/csv/default-a7b284f72a1a62a9/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06c1bfacf1f4681ab58bc34d88d0c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e598ac9b1154bd68ae450ce311bac0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/rohan/.cache/huggingface/datasets/csv/default-a7b284f72a1a62a9/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f24e76eab8f4309b8b1bfd5ca88a710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Split Data\n",
    "random_seed = 42\n",
    "train_df = train.sample(frac=1, random_state=random_seed)\n",
    "#valid_df = train.drop(train_df.index) # select partial training data\n",
    "valid_df = validation\n",
    "\n",
    "#assert len(train) == len(train_df) + len(valid_df), \"Dataset sizes don't add up\" # check for proper split\n",
    "\n",
    "# Create New Data Files\n",
    "valid_df.to_csv('./data_gen/validation_data.csv', index=False)\n",
    "train_df.to_csv('./data_gen/train_data.csv', index=False)\n",
    "#validation.to_csv('./data_gen/test_data.csv', index=False)\n",
    "\n",
    "# Load Data (train + val)\n",
    "training_data = load_dataset(\"csv\", data_files={'train': ['./data_gen/train_data.csv'],'validation': ['./data_gen/validation_data.csv']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score \n",
    "\n",
    "# Helper Functions\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=512)\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1_weighted = f1_score(labels, preds, average=\"weighted\")\n",
    "    f1_macro = f1_score(labels, preds, average=\"macro\") \n",
    "    f1_micro = f1_score(labels, preds, average=\"micro\") \n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1_weighted\": f1_weighted, \"f1_macro\": f1_macro, \"f1_micro\": f1_micro}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1330 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "num_labels = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_ckpt = \"csebuetnlp/banglabert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt, model_max_length=256)\n",
    "\n",
    "model = (AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=num_labels).to(device))\n",
    "training_data_encoded = training_data.map(tokenize, batched=True, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 7  # Change this to the number of layers you want to freeze\n",
    "# for i in range(n):\n",
    "#     for param in model.electra.encoder.layer[i].parameters():\n",
    "#         param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments \n",
    "batch_size = 64\n",
    "logging_steps = len(training_data_encoded[\"train\"]) // batch_size \n",
    "model_name = f\"{model_ckpt}-violence-inciting-text\"\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                  num_train_epochs=10, \n",
    "                                  #num_training_steps=100, \n",
    "                                  learning_rate=2e-5,\n",
    "                                  #warmup_steps=10000,\n",
    "                                  per_device_train_batch_size=batch_size, \n",
    "                                  per_device_eval_batch_size=batch_size, \n",
    "                                  eval_steps=100,\n",
    "                                  logging_steps = 100,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"steps\", \n",
    "                                  save_strategy=\"steps\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  #logging_steps=logging_steps,\n",
    "                                  save_steps = 100, \n",
    "                                  save_total_limit = 2,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  metric_for_best_model=\"f1_macro\",\n",
    "                                  greater_is_better=True,\n",
    "                                  optim='adamw_torch',\n",
    "                                  lr_scheduler_type= \"linear\", #cosine_with_restarts\n",
    "                                  log_level=\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#!sudo apt-get install git-lfs\n",
    "from transformers import Trainer\n",
    "# select Trainer\n",
    "trainer = Trainer(model=model, \n",
    "                  args=training_args,\n",
    "                  compute_metrics=compute_metrics,\n",
    "                  train_dataset=training_data_encoded[\"train\"], \n",
    "                  eval_dataset=training_data_encoded[\"validation\"],\n",
    "                  data_collator=data_collator,\n",
    "                  tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 4542, 465, 3], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('asd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/430 : < :, Epoch 0.02/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 23.70 GiB total capacity; 11.65 GiB already allocated; 21.81 MiB free; 12.98 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[375], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Label Encode.... Use Dataset name as Feature... Find other feature... create word map\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/textclassification/lib/python3.9/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1536\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1537\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1538\u001b[0m )\n\u001b[0;32m-> 1539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/textclassification/lib/python3.9/site-packages/transformers/trainer.py:1809\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1806\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1808\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1809\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1812\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1813\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1814\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1815\u001b[0m ):\n\u001b[1;32m   1816\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1817\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/textclassification/lib/python3.9/site-packages/transformers/trainer.py:2654\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2651\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2653\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2654\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2657\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/textclassification/lib/python3.9/site-packages/transformers/trainer.py:2679\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2678\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2679\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2680\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2681\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/textclassification/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/textclassification/lib/python3.9/site-packages/transformers/models/electra/modeling_electra.py:1004\u001b[0m, in \u001b[0;36mElectraForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1004\u001b[0m discriminator_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melectra\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m discriminator_hidden_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1017\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/miniconda3/envs/textclassification/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/textclassification/lib/python3.9/site-packages/transformers/models/electra/modeling_electra.py:919\u001b[0m, in \u001b[0;36mElectraModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings_project\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    917\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings_project(hidden_states)\n\u001b[0;32m--> 919\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/textclassification/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/textclassification/lib/python3.9/site-packages/transformers/models/electra/modeling_electra.py:590\u001b[0m, in \u001b[0;36mElectraEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    581\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    582\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    583\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    587\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    588\u001b[0m     )\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 590\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/textclassification/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/textclassification/lib/python3.9/site-packages/transformers/models/electra/modeling_electra.py:474\u001b[0m, in \u001b[0;36mElectraLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    464\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    471\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    473\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 474\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/textclassification/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/textclassification/lib/python3.9/site-packages/transformers/models/electra/modeling_electra.py:401\u001b[0m, in \u001b[0;36mElectraAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    393\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    399\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    400\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 401\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    411\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/textclassification/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/textclassification/lib/python3.9/site-packages/transformers/models/electra/modeling_electra.py:337\u001b[0m, in \u001b[0;36mElectraSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     attention_probs \u001b[38;5;241m=\u001b[39m attention_probs \u001b[38;5;241m*\u001b[39m head_mask\n\u001b[0;32m--> 337\u001b[0m context_layer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_layer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m context_layer \u001b[38;5;241m=\u001b[39m context_layer\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    340\u001b[0m new_context_layer_shape \u001b[38;5;241m=\u001b[39m context_layer\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_head_size,)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 23.70 GiB total capacity; 11.65 GiB already allocated; 21.81 MiB free; 12.98 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "trainer.train() # Label Encode.... Use Dataset name as Feature... Find other feature... create word map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 1.137454628944397,\n",
       " 'test_accuracy': 0.8293233082706767,\n",
       " 'test_f1_weighted': 0.8292269151387627,\n",
       " 'test_f1_macro': 0.815951709356554,\n",
       " 'test_f1_micro': 0.8293233082706768,\n",
       " 'test_runtime': 1.8362,\n",
       " 'test_samples_per_second': 724.335,\n",
       " 'test_steps_per_second': 90.95}"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_output = trainer.predict(training_data_encoded[\"validation\"])\n",
    "preds_output.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAggAAAIjCAYAAABml+OWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABF4ElEQVR4nO3deXxM1//H8fckZBFJCAlC7MROq/YSW6nWXnShDaqbfW2p2ltabSltldJStS+l32pRtW+t2lqK2PddSAgiydzfH36mHScqqTBJvJ6Pxzwe5sy5537u5Jp5z73nztgsy7IEAADwD26uLgAAAKQ+BAQAAGAgIAAAAAMBAQAAGAgIAADAQEAAAAAGAgIAADAQEAAAgIGAAAAADAQEIJU5fPiwbDabpkyZ4mgbPHiwbDbbA6/FZrNp8ODBD3y9SfX777+ratWq8vHxkc1m0/bt21N0/FWrVslms2nVqlUpOm56kNr3Ddw7AgJSzK03sfPnzyf6eKlSpVSzZs0HWxTSrbi4OLVs2VKRkZEaPXq0vv32W+XLl8/VZaU5GzZs0ODBg3Xp0iVXl4JUJoOrCwBwd++884769u3r6jJSlQMHDujIkSOaOHGiOnTocF/WUaNGDV27dk0eHh73ZfzUYMOGDRoyZIjatm2rLFmyJHm5a9euKUMG3kLSM44gAHdx/fp12e12l9aQIUMGeXl5ubSG1Obs2bOSlKw3teRyc3OTl5eX3Nx4qZQku92u69evS5K8vLwICOkcez1c5tb53Tlz5ui9995Tnjx55OXlpTp16mj//v1JGiN//vxq2LCh1q1bp4oVK8rLy0sFCxbU1KlTjb4HDx5Uy5YtFRAQoEyZMqly5cr68ccfE61p1qxZeuedd5Q7d25lypRJ0dHRatu2rTJnzqyjR4+qYcOGypw5s3Lnzq3PP/9ckrRjxw7Vrl1bPj4+ypcvn2bMmOE0dmRkpHr37q3SpUsrc+bM8vPzU4MGDfTHH3/cdTtvn4PQtm1b2Wy2RG//PC8cGxurQYMGqXDhwvL09FRISIjefPNNxcbGOo0fGxurHj16KDAwUL6+vmrcuLGOHz9+17puuX79ugYPHqyiRYvKy8tLuXLlUvPmzXXgwAFHn5iYGPXq1UshISHy9PRUaGioPvroI93+g7I2m02dO3fWwoULVapUKXl6eqpkyZJasmSJ0/aHhYVJklq2bCmbzeY4fVWzZs1ET2W1bdtW+fPnd2qbNWuWypcvL19fX/n5+al06dIaM2aM4/E7zUGYO3euypcvL29vb2XPnl1t2rTRiRMnjPVlzpxZJ06cUNOmTZU5c2YFBgaqd+/eSkhIuOtzemvfXrVqlR577DF5e3urdOnSjlq+++47lS5dWl5eXipfvry2bdvmtPyff/6ptm3bqmDBgvLy8lLOnDnVvn17XbhwwdFn8ODB6tOnjySpQIECjn3o8OHDkv7+W0yfPl0lS5aUp6en4+/wz33t2rVrKlasmIoVK6Zr1645xo+MjFSuXLlUtWrVJG0zUhfiH1zu/fffl5ubm3r37q2oqCiNHDlSrVu31m+//Zak5ffv368WLVro5ZdfVnh4uL7++mu1bdtW5cuXV8mSJSVJZ86cUdWqVXX16lV17dpV2bJl0zfffKPGjRtr3rx5atasmdOYw4YNk4eHh3r37q3Y2FjHIeaEhAQ1aNBANWrU0MiRIzV9+nR17txZPj4+6t+/v1q3bq3mzZtr/Pjxeumll1SlShUVKFBA0s2AsnDhQrVs2VIFChTQmTNnNGHCBIWFhWnXrl0KDg5O8nP22muvqW7duk5tS5Ys0fTp0xUUFCTp5qe9xo0ba926dXr11VdVvHhx7dixQ6NHj9bevXu1cOFCx7IdOnTQtGnT9MILL6hq1apasWKFnn766STVkpCQoIYNG2r58uV67rnn1K1bN12+fFnLli3Tzp07VahQIVmWpcaNG2vlypV6+eWXVa5cOS1dulR9+vTRiRMnNHr0aKcx161bp++++04dO3aUr6+vxo4dq2eeeUZHjx5VtmzZ9Nprryl37twaPny4unbtqgoVKihHjhxJfv4kadmyZXr++edVp04dffDBB5Kk3bt3a/369erWrdsdl5syZYratWunChUqaMSIETpz5ozGjBmj9evXa9u2bU5HNBISElS/fn1VqlRJH330kX755Rd9/PHHKlSokN5444271rh//3698MILeu2119SmTRt99NFHatSokcaPH6+3335bHTt2lCSNGDFCrVq1UkREhONox7Jly3Tw4EG1a9dOOXPm1F9//aUvv/xSf/31l3799VfZbDY1b95ce/fu1cyZMzV69Ghlz55dkhQYGOioYcWKFZozZ446d+6s7NmzGyFLkry9vfXNN9+oWrVq6t+/v0aNGiVJ6tSpk6KiojRlyhS5u7vfdXuRylhAChk0aJAlyTp37lyij5csWdIKCwtz3F+5cqUlySpevLgVGxvraB8zZowlydqxY8dd15kvXz5LkrVmzRpH29mzZy1PT0+rV69ejrbu3btbkqy1a9c62i5fvmwVKFDAyp8/v5WQkOBUU8GCBa2rV686rSs8PNySZA0fPtzRdvHiRcvb29uy2WzWrFmzHO179uyxJFmDBg1ytF2/ft2xnlsOHTpkeXp6WkOHDnVqk2RNnjzZ0Xbrub2Tffv2Wf7+/tYTTzxhxcfHW5ZlWd9++63l5ubmtM2WZVnjx4+3JFnr16+3LMuytm/fbkmyOnbs6NTvhRdeMLYhMV9//bUlyRo1apTxmN1utyzLshYuXGhJst59912nx1u0aGHZbDZr//79jjZJloeHh1PbH3/8YUmyPv30U0fbrb/V3LlzncYMCwtz2s9uCQ8Pt/Lly+e4361bN8vPz8/xfCXm1jpWrlxpWZZl3bhxwwoKCrJKlSplXbt2zdFv0aJFliRr4MCBTuuT5PS3tSzLeuSRR6zy5cvfcZ233Nq3N2zY4GhbunSpJcny9va2jhw54mifMGGCU52WZRn7r2VZ1syZM43/Lx9++KElyTp06JDRX5Ll5uZm/fXXX4k+dvu+0a9fP8vNzc1as2aNNXfuXEuS9cknn9x1W5E6cYoBLteuXTunSWDVq1eXdPMTd1KUKFHCsYx089NPaGio0/I//fSTKlasqMcff9zRljlzZr366qs6fPiwdu3a5TRmeHi4vL29E13fPyfEZcmSRaGhofLx8VGrVq0c7aGhocqSJYtTDZ6eno5PdwkJCbpw4YIyZ86s0NBQbd26NUnbmpiYmBg1a9ZMWbNm1cyZMx2f1ObOnavixYurWLFiOn/+vONWu3ZtSdLKlSsdz40kde3a1Wnc7t27J2n98+fPV/bs2dWlSxfjsVunRX766Se5u7sb6+jVq5csy9LixYud2uvWratChQo57pcpU0Z+fn5J3ieSIkuWLIqJidGyZcuSvMzmzZt19uxZdezY0WlOyNNPP61ixYoZp6wk6fXXX3e6X7169WTt21WqVHHcr1SpkiSpdu3ayps3r9H+z3H/uf9ev35d58+fV+XKlSUpWftbWFiYSpQokaS+gwcPVsmSJRUeHq6OHTsqLCzM+Jsj7SAg4IFK7Fr+f77QSVLWrFklSRcvXpQkXblyRadPn3bczp0796/L3xrj1vKSdOTIEYWGhhr9ihcv7nj8n26dFridl5eX0+FXSfL391eePHmMbfP393eqwW63a/To0SpSpIg8PT2VPXt2BQYG6s8//1RUVFSi60uKV155RQcOHNCCBQuULVs2R/u+ffv0119/KTAw0OlWtGhRSX9P8jty5Ijc3Nyc3pAlJfp8JebAgQMKDQ391wlrR44cUXBwsHx9fZ3a7/T8J+Vveq86duyookWLqkGDBsqTJ4/at2/vNM8hMbfqTOy5KVasmLEdie0vydmO258Hf39/SVJISEii7f8cNzIyUt26dVOOHDnk7e2twMBAx36dnP3tTv8XEuPh4aGvv/5ahw4d0uXLlzV58mSXfH8HUgZzEJBibn2i+uckpX+6evVqojPx73Ru0vr/yWsfffSRhgwZ4mjPly+fYxJVUpb/L+509OBO60pKDcOHD9eAAQPUvn17DRs2TAEBAXJzc1P37t3/81USY8aM0cyZMzVt2jSVK1fO6TG73a7SpUs7zgff7vY3mdTkXv6mNpst0X63T5ILCgrS9u3btXTpUi1evFiLFy/W5MmT9dJLL+mbb775b4Xf5l7Pu9/L/taqVStt2LBBffr0Ubly5ZQ5c2bZ7XY9+eSTydrf7vR/4U6WLl0q6eZRi3379iUrYCB1ISAgxdz6kpqIiAjjzefq1as6duyY6tWrl+xxX3rpJadTA8l9wbpVW0REhNG+Z88ex+P327x581SrVi199dVXTu2XLl1yTA5LjrVr16p3797q3r27WrdubTxeqFAh/fHHH6pTp86/forLly+f7Ha740jALYk9X4kpVKiQfvvtN8XFxSljxox3XMcvv/yiy5cvOx1FuB/Pf9asWRM9hH/7p3vp5ifeRo0aqVGjRrLb7erYsaMmTJigAQMGqHDhwoluh3Tzubl1quaWiIiIVPNFTRcvXtTy5cs1ZMgQDRw40NG+b98+o29KfsL/888/NXToULVr107bt29Xhw4dtGPHDscRDqQtnGJAiqlTp448PDz0xRdfGJ9QvvzyS8XHx6tBgwbJHrdgwYKqW7eu41atWrVkj/HUU09p06ZN2rhxo6MtJiZGX375pfLnz5/kc6z3wt3d3fhkO3fuXOPyuKQ4deqUWrVqpccff1wffvhhon1atWqlEydOaOLEicZj165dU0xMjCQ5/iZjx4516vPJJ58kqZZnnnlG58+f12effWY8dmt7n3rqKSUkJBh9Ro8eLZvN9p/2izspVKiQ9uzZ43Qq6o8//tD69eud+v3zcj/p5ncelClTRpKMy0BveeyxxxQUFKTx48c79Vm8eLF2796d5Cs/7rdbRxhu398S+5v6+PhI0j1/k2JcXJzatm2r4OBgjRkzRlOmTNGZM2fUo0ePexoXrsMRBKSYoKAgDRw4UO+8845q1Kihxo0bK1OmTNqwYYNmzpypevXqqVGjRi6prW/fvpo5c6YaNGigrl27KiAgQN98840OHTqk+fPnP5AvwmnYsKHj01XVqlW1Y8cOTZ8+XQULFkz2WF27dtW5c+f05ptvatasWU6PlSlTRmXKlNGLL76oOXPm6PXXX9fKlStVrVo1JSQkaM+ePZozZ46WLl2qxx57TOXKldPzzz+vcePGKSoqSlWrVtXy5cuT/F0UL730kqZOnaqePXtq06ZNql69umJiYvTLL7+oY8eOatKkiRo1aqRatWqpf//+Onz4sMqWLauff/5Z33//vbp3727Mf7gX7du316hRo1S/fn29/PLLOnv2rMaPH6+SJUsqOjra0a9Dhw6KjIxU7dq1lSdPHh05ckSffvqpypUr55gbcbuMGTPqgw8+ULt27RQWFqbnn3/ecZlj/vz5U82boZ+fn+NS3Li4OOXOnVs///yzDh06ZPQtX768JKl///567rnnlDFjRjVq1MgRHJLq3Xff1fbt27V8+XL5+vqqTJkyjteDFi1a6KmnnkqRbcMD5KrLJ5B+TZs2zapcubLl4+NjeXp6WsWKFbOGDBliXb9+3anfnS5TS+wyvzvJly+f9fTTTxvtiV3qduDAAatFixZWlixZLC8vL6tixYrWokWLklSTZd28bM3HxyfRdZUsWfKutV2/ft3q1auXlStXLsvb29uqVq2atXHjRqPWpFzmGBYWZklK9PbPS89u3LhhffDBB1bJkiUtT09PK2vWrFb58uWtIUOGWFFRUY5+165ds7p27Wply5bN8vHxsRo1amQdO3YsSZc5WtbNS+r69+9vFShQwMqYMaOVM2dOq0WLFtaBAwccfS5fvmz16NHDCg4OtjJmzGgVKVLE+vDDDx2XQt4iyerUqVOiz2d4eLjj/r/9raZNm2YVLFjQ8vDwsMqVK2ctXbrUuMxx3rx5Vr169aygoCDLw8PDyps3r/Xaa69Zp06dMtbxz8sHLcuyZs+ebT3yyCOWp6enFRAQYLVu3do6fvy4U5877S93u2T1n9ub2L6d2PNza5/58MMPHW3Hjx+3mjVrZmXJksXy9/e3WrZsaZ08eTLRv+mwYcOs3LlzW25ubk6XPN7pb3HrsVvjbNmyxcqQIYPVpUsXpz7x8fFWhQoVrODgYOvixYt33WakLjbLuoeZXAAAIF1iDgIAADAQEAAAgIGAAAAADAQEAABgICAAAAADAQEAABjS9Bcl2e12nTx5Ur6+vvwgCAAAd2FZli5fvqzg4OC7fkFcmg4IJ0+eTNU/OAMAQGp07Ngx5cmT51/7pOmAcOtHXzxKhMvm7uHiapCerZ8/1NUl4CHg55WmX5KRBly5fFmPlixo/PR6YtL03njrtILN3YOAgPsqs6+fq0vAQ8DXO02/JCMNScppeSYpAgAAAwEBAAAYCAgAAMBAQAAAAAYCAgAAMBAQAACAgYAAAAAMBAQAAGAgIAAAAAMBAQAAGAgIAADAQEAAAAAGAgIAADAQEAAAgIGAAAAADAQEAABgICAAAAADAQEAABgICAAAwEBAAAAABgICAAAwEBAAAICBgAAAAAwEBAAAYCAgAAAAAwEBAAAYCAgAAMBAQAAAAAYCAgAAMBAQAACAgYAAAAAMBAQAAGAgIAAAAAMBAQAAGAgIAADAQEAAAAAGAgIAADAQEAAAgIGAAAAADAQEAABgICAAAAADAQEAABgICAAAwEBAAAAABgICAAAwEBAAAICBgAAAAAwEBAAAYCAgAAAAAwEBAAAYCAgAAMBAQAAAAAYCAgAAMBAQAACAgYAAAAAMBAQAAGAgIAAAAAMBAQAAGAgIAADAQEAAAAAGAgIAADAQEAAAgIGAAAAADAQEAABgICAAAAADAQEAABgICAAAwEBAAAAAhgyuLgD3rkPLGurSpo6Csvlp574TeuvDudq668gd+7/+fE21f6a68uTIqsioGH2/fJuGfv4/xd6Id/TJFeivwV2aqG6VkvL2yqhDx8+r09Bp2r776IPYJKRCs37YoG/mrdaFi5dVtGAuvfVGE5UOzZto3/1HTuuLb3/Wrn0ndOrsRfV+tZHaNKtu9DtzPkpjvv5J6zdH6HrsDYUEZ9eQHi1VsmjI/d4cpFJTF6zTl7NW6lzkZRUvHKzBXZupXPF8ifbde+i0Rk9erB0Rx3XizEUN6NRE7VuG3dOY+BtHENK4Zk88qne7N9MHkxar5osfaOe+E5r/aSdlz5o50f4t6j+mQZ2aaOTExarU6l11GTZdzZ4orwEdGzv6+Pt6a8mknoqLt6tlt3Gq/Ox7eueT73Qp+uqD2iykMktXb9fHX/6g11rX1cxPu6logVzq+M5Xirx0JdH+16/HKXfOAHVr10DZs/om2if68lW17TVOGTK467Nh7fXdhN7q2aGh/DJnup+bglRs0Yptem/c9+rWtr4WTeyp4oWCFd7nS52/eDnR/tdibygkVza99WpDBQYkvp8ld0z8LVUEhM8//1z58+eXl5eXKlWqpE2bNrm6pDSj4wu1NXXhBs344VdFHDqtniNm6er1G2rTuEqi/SuWKaDf/jyoeUs369ipSK38bY/m/7xZ5Uv+naa7hz+hE2cuqvPQadq664iOnryglb/t0eET5x/UZiGV+XbBWjVvUElN61VQoXw59E6X5vLyzKiFP/+eaP9SoSHq2aGhnqxZThkzJn6gcvLcVcoZ6K+hPVupdGhe5c4ZoKrliyokONv93BSkYpPmrtazT1dWywYVVSR/Tr3Xs4W8vTJq7k+JvyeULZZXb7/RWI3qPCKPO+xnyR0Tf3N5QJg9e7Z69uypQYMGaevWrSpbtqzq16+vs2fPurq0VC9jBneVKxaiVZsiHG2WZWn1pghVKF0g0WU2/XlI5YqF6NESNwNBvtzZ9ETVklq2/i9Hnyerl9a23Uc1eUR77V06QqunvaWXmla9vxuDVCsuLl67951QpXKFHW1ubm6qVK6I/tx951NZd7P6110qUSSPer/3rWo9N0TPdvpE8xf/lhIlIw26ERevnRHH9Xj5oo42Nzc3VStfVFt3HU41Yz5MXB4QRo0apVdeeUXt2rVTiRIlNH78eGXKlElff/21q0tL9bJlyawMGdx1LtL5UNm5yGgFZfNLdJl5Szdr+IQftXhSD53dOEbbFw7R+i37NGrKz44++XNnV/tnquvgsXN6psvn+nr+Or3fq4Wee7rSfd0epE4Xo2OUYLcr222nCrJlzXxPh2mPn47U3B9/Vd7c2fXFux3U8unKGjn+e/1v2eZ7LRlp0MWom/tZ9ttOFWTP6mu8xrlyzIeJSycp3rhxQ1u2bFG/fv0cbW5ubqpbt642btxo9I+NjVVsbKzjfnR09AOpMz2p9mgR9WxXX70/mK0tO4+oQEh2vd+rhXqff1IffbVEkuTmZtP23Uc1bNwPkqQde4+reMFcatf8cc36kU94SBl2y1KJInnUtW0DSVKxwrl14MgZzfvpVzV+4jEXVwfApUcQzp8/r4SEBOXIkcOpPUeOHDp9+rTRf8SIEfL393fcQkIe7pnOFy5dUXx8gjE5JzDAT2cvJB6e+r/+tOb8tEnffr9Ruw6c1I+r/tSwcT+oR9t6stlskqQz56O156Dz87/38GnlyZn1/mwIUrWsfj5yd3PThduOFly4eOWOExCTIjDAV4XyBjm1FQgJ0qlzl/7zmEi7svrf3M/O3/bJ/vzFy3ecgOiKMR8mLj/FkBz9+vVTVFSU43bs2DFXl+RScfEJ2r7nmMIqhDrabDabalQoqt93HEp0GW8vD9ntllNbQoL9/5e9ef+3Pw6qSD7nF+5CeYN0/HRkClaPtCJjxgwqXiS3Nm3f72iz2+3atH2/ytzDpWJlS+TX4ePnnNqOnDinXEEE0YeRR8YMKhWaR+u37nO02e12bdiyT4+WyJ9qxnyYuDQgZM+eXe7u7jpz5oxT+5kzZ5QzZ06jv6enp/z8/JxuD7txM1bopaZV9dzTlVQ0fw6N6vusfLw9Nf2HXyVJXwx+UQM7/X0J45K1O9XumcfV/InyyhucTTUrFtPbrzfUkrU7HMFh3MwVeqx0AfVsW08F8mRXi/qPKbxZNU2au8Yl2wjXe7FZdX23ZJP+t2yzDh49o/c+W6BrsTfU5P9PBbzz0SyNnbzY0T8uLl57DpzUngMnFR8fr7MXorTnwEkdPfn3lTBtmlbXjj1HNWnWCh09eV4/rdym+Yt/07MNE78CB+lfh5ZhmrXoV81f8rv2Hzmjd0bP09XrN9SiQUVJUs/hMzTyy0WO/jfi4rVr3wnt2ndCcfEJOn0+Srv2nXAKnncbE3fm0jkIHh4eKl++vJYvX66mTZtKupnuli9frs6dO7uytDRjwbKtyp4ls95+7WkFZfPVjr0n1KLr544JOHlyBshu/X3E4KOvl8iyLPV/o6FyBfrrwqUrWrJ2p2O+gSRt23VUL/aZqIGdGqtPhwY6cvKC3h41X3OXMHnsYVU/rJwuRsXoi2k/63zkZYUWCta4YS87Ji6eOnvJcYpKks5GRuu5zp847k+dv0ZT569R+dIF9dXI1yXdvBRy1ICXNHbKEn054xflzhmgPq811tO1H32g24bUo2HtR3Th0hWNmrxE5yOjVbxwbk0Z+arjdMDJMxfl9s/97Hy0nn7lY8f9ibNXaeLsVapUtpBmjemUpDFxZzbLsqy7d7t/Zs+erfDwcE2YMEEVK1bUJ598ojlz5mjPnj3G3ITbRUdHy9/fX56lX5HN3eMBVYyH0fbFI11dAh4C/t58uS3ur8vR0SqaN1BRUVF3PQrv8r3x2Wef1blz5zRw4ECdPn1a5cqV05IlS+4aDgAAwP3j8oAgSZ07d+aUAgAAqUiauooBAAA8GAQEAABgICAAAAADAQEAABgICAAAwEBAAAAABgICAAAwEBAAAICBgAAAAAwEBAAAYCAgAAAAAwEBAAAYCAgAAMBAQAAAAAYCAgAAMBAQAACAgYAAAAAMBAQAAGAgIAAAAAMBAQAAGAgIAADAQEAAAAAGAgIAADAQEAAAgIGAAAAADAQEAABgICAAAAADAQEAABgICAAAwEBAAAAABgICAAAwEBAAAICBgAAAAAwEBAAAYCAgAAAAAwEBAAAYCAgAAMBAQAAAAAYCAgAAMBAQAACAgYAAAAAMBAQAAGAgIAAAAAMBAQAAGAgIAADAQEAAAAAGAgIAADAQEAAAgIGAAAAADAQEAABgICAAAAADAQEAABgICAAAwEBAAAAABgICAAAwEBAAAICBgAAAAAwEBAAAYCAgAAAAAwEBAAAYCAgAAMBAQAAAAAYCAgAAMBAQAACAgYAAAAAMBAQAAGAgIAAAAAMBAQAAGAgIAADAkMHVBaSEHT8Ol6+fn6vLQDpWoOVYV5eAh8DxBd1dXQLSuYwZkn5cgCMIAADAQEAAAAAGAgIAADAQEAAAgIGAAAAADAQEAABgICAAAAADAQEAABgICAAAwEBAAAAABgICAAAwEBAAAICBgAAAAAwEBAAAYCAgAAAAAwEBAAAYCAgAAMBAQAAAAAYCAgAAMBAQAACAgYAAAAAMBAQAAGAgIAAAAAMBAQAAGAgIAADAQEAAAAAGAgIAADAQEAAAgIGAAAAADAQEAABgICAAAAADAQEAABgICAAAwEBAAAAABgICAAAwEBAAAICBgAAAAAwEBAAAYCAgAAAAAwEBAAAYCAgAAMBAQAAAAAYCAgAAMBAQAACAgYAAAAAMGZLS6X//+1+SB2zcuPF/LgYAAKQOSQoITZs2TdJgNptNCQkJ91IPAABIBZIUEOx2+/2uAwAApCL3NAfh+vXrKVUHAABIRZIdEBISEjRs2DDlzp1bmTNn1sGDByVJAwYM0FdffZXiBQIAgAcv2QHhvffe05QpUzRy5Eh5eHg42kuVKqVJkyalaHEAAMA1kh0Qpk6dqi+//FKtW7eWu7u7o71s2bLas2dPihYHAABcI9kB4cSJEypcuLDRbrfbFRcXlyJFAQAA10p2QChRooTWrl1rtM+bN0+PPPJIihQFAABcK0mXOf7TwIEDFR4erhMnTshut+u7775TRESEpk6dqkWLFt2PGgEAwAOW7CMITZo00Q8//KBffvlFPj4+GjhwoHbv3q0ffvhBTzzxxP2oEQAAPGDJPoIgSdWrV9eyZctSuhYAAJBK/KeAIEmbN2/W7t27Jd2cl1C+fPkUKwoAALhWsgPC8ePH9fzzz2v9+vXKkiWLJOnSpUuqWrWqZs2apTx58qR0jQAA4AFL9hyEDh06KC4uTrt371ZkZKQiIyO1e/du2e12dejQ4X7UCAAAHrBkH0FYvXq1NmzYoNDQUEdbaGioPv30U1WvXj1FiwMAAK6R7CMIISEhiX4hUkJCgoKDg1OkKAAA4FrJDggffvihunTpos2bNzvaNm/erG7duumjjz5K0eIAAIBrJOkUQ9asWWWz2Rz3Y2JiVKlSJWXIcHPx+Ph4ZciQQe3bt1fTpk3vS6EAAODBSVJA+OSTT+5zGQAAIDVJUkAIDw+/33UAAIBU5D9/UZIkXb9+XTdu3HBq8/Pzu6eCAACA6yV7kmJMTIw6d+6soKAg+fj4KGvWrE43AACQ9iU7ILz55ptasWKFvvjiC3l6emrSpEkaMmSIgoODNXXq1PtRIwAAeMCSfYrhhx9+0NSpU1WzZk21a9dO1atXV+HChZUvXz5Nnz5drVu3vh91AgCAByjZRxAiIyNVsGBBSTfnG0RGRkqSHn/8ca1ZsyZlqwMAAC6R7CMIBQsW1KFDh5Q3b14VK1ZMc+bMUcWKFfXDDz84frwJD9bUBev05ayVOhd5WcULB2tw12YqVzxfon33Hjqt0ZMXa0fEcZ04c1EDOjVR+5Zh9zQmHg4dGpZTl2cqKCirj3YeOqe3vliurXtPJ9r3h/ef1eNlQoz2nzcd1LODv5MkBWbJpMHtaqjWo/nl7+OpDTuP663xy3Xw5KX7uRlI5abMX6vxM1fcfO0pFKxhPZ7RIyXu/NqzaMV2fTjpJx0/Han8eQL19huNVKdKCcfjMVdjNXz8D1q6docuRl1V3uAAtW9RQy82rfYgNidNS/YRhHbt2umPP/6QJPXt21eff/65vLy81KNHD/Xp0yfFC8S/W7Rim94b9726ta2vRRN7qnihYIX3+VLnL15OtP+12BsKyZVNb73aUIEBvikyJtK/ZjVC9e4rNfXBjI2q2eVb7Tx4VvOHtVB2/0yJ9n/x3e8V2nqc41bl9cmKT7Br4boIR59pA5oqfy5/tR66UGFdpur42WgtHN5KmTwzPqjNQirzv+VbNfSzherR7kkt/qq3ShTOrTY9x9/xtWfzjkPqNGSqnmtYWUu+7q0nq5dWh35fac/BU44+Qz5dqFW/7dHYAW20anpfvdwyTO+Mnq+f1+18UJuVZiU7IPTo0UNdu3aVJNWtW1d79uzRjBkztG3bNnXr1i1ZY61Zs0aNGjVScHCwbDabFi5cmNxyHnqT5q7Ws09XVssGFVUkf06917OFvL0yau5PmxLtX7ZYXr39RmM1qvOIPDImfgApuWMi/evY7DFNXbJDM5btVMSxC+r52TJdjY1Tm3qlEu1/6cp1nb141XGr+Ug+XY2N0/dr90qSCuXOqorFg9Xrs1+0bd9p7T9xUT0/XyYvjwx6pmaxB7lpSEW+nLVKzzeqomefrqSiBXLq/T4t5eXloVmLfku0/1dzV6tmpWJ644XaKpI/p/q88pRKFc2jKfPXOvps2XlILRtUUNVHiygkVza1aVJVJQoFa/uuIw9qs9KsZAeE2+XLl0/NmzdXmTJlkr1sTEyMypYtq88///xey3go3YiL186I43q8fFFHm5ubm6qVL6qtuw6nmjGRtmXM4KZyhXNo1fa/X1AtS1q9/agqFEvaD7S9WL+0vlu9R1djb/7Qm2dGd0nS9RvxTmPeiItX5RK5U7B6pBU34uK1Y+9xVX/M+bWn+mNFtfWvw4kus2XnYaf+khRWqZi27Py7f/lSBbRs3U6dOndJlmVp/dZ9OnjsnGpUJIjeTZLmIIwdOzbJA946upAUDRo0UIMGDZLcH84uRsUowW5X9ttOFWTP6qsDR8+mmjGRtmXz81YGdzeduxjj1H7uUoyKhATcdflHi+ZUifyB6vLJUkfb3mOROnY2WgPb1VCPT3/W1etx6tj0MeUO9FOOAJ8U3wakfpFRMUpIsBunPrMH+Gr/kTOJLnMu8rKyZ3XuH5jVV+ciox33h/V4Rm+NnK0KzQYrg7ub3NxsGvnms6pcrlDKb0Q6k6SAMHr06CQNZrPZkhUQkis2NlaxsbGO+9HR0f/SG0Bq8GK90vrr0DmnCY3xCXa9+O73+rRbfR2e00XxCXat2nZEy34/6PTDcMC9mjxvjbb+dViT3++g3DkD9NsfB9R/1HzlyO6v6hVCXV1eqpakgHDo0KH7XUeSjBgxQkOGDHF1GalGVn8fubu56Xyk8wSe8xcv33ECoivGRNp2Ifqa4hPsCszq/Mk+MIuPzkbG3GGpmzJ5ZlTzsGIaPm298dgf+8+oRpep8svkoYwZ3HUh+pqWjW6t7fsSvzIC6VuAv4/c3d107vbXnsjLCsqW+Ff4Bwb4GhMYz128rMCAm/2vxd7QB1/+qEnD26tO1ZKSpBKFg/XXvhMaP3MlAeEu7nkOwoPUr18/RUVFOW7Hjh1zdUku5ZExg0qF5tH6rfscbXa7XRu27NOjJfKnmjGRtsXF27V9/xmFlc3raLPZpBrl8ur3PSf/ddkm1YvKI6O75qzYdcc+0Vdv6EL0NRUMzqJHCufQTxv3p1jtSDs8MmZQ6aJ5tG6L82vPui179WjJ/IkuU75Ufq3bvM+pbe3vESpf6mb/+Hi74uITjKNS7m42WZaVovWnR/f0Y00Pmqenpzw9PV1dRqrSoWWYeo2YqTKhISpbPK++nrdaV6/fUIsGFSVJPYfPUM7sfnrz1YaSbk4E2n/45vm8uPgEnT4fpV37TiiTt4fy5wlM0ph4+IxbsFnjejbQtn1ntHXvKb3RpLx8PDNq+rKbl4p90auBTl24oqFT1jot92K90vpp435dvHzdGLPJ40V1Puqajp+LVon82fX+a7X146/7tXIbs8sfVq8+V1M93puhssVCVK54Xk2as1rXrt3Qs09XkiR1GzZNOQP91e/1RpKkl1uGqUXnTzVh5krVqVpC3/+yVX/uOaYP3nxWkuTr46XK5QrpvXH/k5dnRuXJGaBft+/XvCWbNahLE5dtZ1qRpgICTA1rP6ILl65o1OQlOh8ZreKFc2vKyFcdpwNOnrkot3+k57Pno/X0Kx877k+cvUoTZ69SpbKFNGtMpySNiYfPgjURyu6XSW+/WE1BWTNpx8FzajFwns5duipJyhPoJ7vd+RNZ4dxZVaVUHjXrPzfRMXME+Oi9V2oqMIuPzlyM0azlf+nDmRvv+7Yg9Wpc51FduBSjjyYt1rnIaJUonFvffvya47XnxJmLcnP7+/XssdIF9NmglzRy4o/64MtFKpAnUJNGvKxiBXM5+owbEq73JyxSl6HTdCn6qvLkzKq3Xn2KL0pKApvlwuMsV65c0f79Nw8nPvLIIxo1apRq1aqlgIAA5c2b9y5L35yk6O/vr71Hz8mXn5nGfVSgZdKv5AH+q+MLuru6BKRzl6OjVSA4m6KiouR3l/dNlx5B2Lx5s2rVquW437NnT0lSeHi4pkyZ4qKqAADAf5qkuHbtWrVp00ZVqlTRiRMnJEnffvut1q1bl6xxatasKcuyjBvhAAAA10p2QJg/f77q168vb29vbdu2zfG9BFFRURo+fHiKFwgAAB68ZAeEd999V+PHj9fEiROVMePfP6pSrVo1bd26NUWLAwAArpHsgBAREaEaNWoY7f7+/rp06VJK1AQAAFws2QEhZ86cjisP/mndunUqWLBgihQFAABcK9kB4ZVXXlG3bt3022+/yWaz6eTJk5o+fbp69+6tN954437UCAAAHrBkX+bYt29f2e121alTR1evXlWNGjXk6emp3r17q0uXLvejRgAA8IAlOyDYbDb1799fffr00f79+3XlyhWVKFFCmTNnvh/1AQAAF/jPX5Tk4eGhEiVKpGQtAAAglUh2QKhVq9a//l77ihUr7qkgAADgeskOCOXKlXO6HxcXp+3bt2vnzp0KDw9PqboAAIALJTsgjB49OtH2wYMH68qVK/dcEAAAcL3/9FsMiWnTpo2+/vrrlBoOAAC4UIoFhI0bN8rLyyulhgMAAC6U7FMMzZs3d7pvWZZOnTqlzZs3a8CAASlWGAAAcJ1kBwR/f3+n+25ubgoNDdXQoUNVr169FCsMAAC4TrICQkJCgtq1a6fSpUsra9as96smAADgYsmag+Du7q569erxq40AAKRzyZ6kWKpUKR08ePB+1AIAAFKJZAeEd999V71799aiRYt06tQpRUdHO90AAEDal+Q5CEOHDlWvXr301FNPSZIaN27s9JXLlmXJZrMpISEh5asEAAAPVJIDwpAhQ/T6669r5cqV97MeAACQCiQ5IFiWJUkKCwu7b8UAAIDUIVlzEP7tVxwBAED6kazvQShatOhdQ0JkZOQ9FQQAAFwvWQFhyJAhxjcpAgCA9CdZAeG5555TUFDQ/aoFAACkEkmeg8D8AwAAHh5JDgi3rmIAAADpX5JPMdjt9vtZBwAASEWS/VXLAAAg/SMgAAAAAwEBAAAYCAgAAMBAQAAAAAYCAgAAMBAQAACAgYAAAAAMBAQAAGAgIAAAAAMBAQAAGAgIAADAQEAAAAAGAgIAADAQEAAAgIGAAAAADAQEAABgICAAAAADAQEAABgICAAAwEBAAAAABgICAAAwEBAAAICBgAAAAAwEBAAAYCAgAAAAAwEBAAAYCAgAAMBAQAAAAAYCAgAAMBAQAACAgYAAAAAMBAQAAGAgIAAAAAMBAQAAGAgIAADAQEAAAAAGAgIAADAQEAAAgIGAAAAADBlcXUBK8PfxkJ+Ph6vLQDp2YVEvV5eAh0C2uoNdXQLSOSs+Nsl9OYIAAAAMBAQAAGAgIAAAAAMBAQAAGAgIAADAQEAAAAAGAgIAADAQEAAAgIGAAAAADAQEAABgICAAAAADAQEAABgICAAAwEBAAAAABgICAAAwEBAAAICBgAAAAAwEBAAAYCAgAAAAAwEBAAAYCAgAAMBAQAAAAAYCAgAAMBAQAACAgYAAAAAMBAQAAGAgIAAAAAMBAQAAGAgIAADAQEAAAAAGAgIAADAQEAAAgIGAAAAADAQEAABgICAAAAADAQEAABgICAAAwEBAAAAABgICAAAwEBAAAICBgAAAAAwEBAAAYCAgAAAAAwEBAAAYCAgAAMBAQAAAAAYCAgAAMBAQAACAgYAAAAAMBAQAAGAgIAAAAAMBAQAAGAgIAADAQEAAAAAGAgIAADAQEAAAgIGAAAAADAQEAABgICAAAAADAQEAABgICAAAwEBAAAAABgICAAAwEBAAAICBgAAAAAwEBAAAYCAgAAAAAwEBAAAYCAgAAMBAQAAAAAYCAgAAMGRwdQG4dxPnrNan05br7IVolSqSWx/0aanyJfPfsf/CX7Zq+PgfdfTUBRUMCdTgLk1Vr1rJRPv2GDFTU75br+E9ntEbL9S6T1uAtGDS3DX6bPrN/axkkdx6v1eLf93Pvl++TcMnLNKxU5EqGBKoQZ2a6Il/7Gedhn6rWT9uclqmduXimjum4/3aBKQBHZpUVJdnqyooILN2Hjijtz79SVv3nLhj/9efqaz2jSsoT5C/IqOu6vs1uzR04i+KjYuXJPV4vroaVi+uInmz63psnDb9dUyDJy7T/mMXHtQmpVkcQUjjvvt5i975ZIHe6tBAq759S6WK5NYzXT7XucjLifb/7Y+D6vDOFLVpUkWrp/XV02Fl1ab3l9q1/6TRd9HKP7R5x2HlCvS/35uBVG7Bsi0aMGaB+rzcQCu+eVOlCudWy27j7rifbfrzoF4ZMEVtGlXRyqlv6akaZfTimxO1+4DzflanSnHt+uk9x23isLYPYGuQWjWrWVLvvlFfH0xdpZqvTdDOA6c1/4MXlT2LT6L9W9QurUGv1NXIb1apUtvP1OWj79WsZkkN6FDH0adq2Xya9P0m1es8Uc37TFXGDO76buRLyuSV8UFtVprl0oAwYsQIVahQQb6+vgoKClLTpk0VERHhypLSnHEzVuilplXVunEVFSuYS6P6PadMXh6a9r+NifafMGuV6lQprq4v1lVogZzq/0ZDlS0WoolzVzv1O3n2kt76aK6+HNZWGTK4P4hNQSo2buZKvdikilo3qqxiBXPp477PytvLQ9N/uMN+NnuV6lQuri7/v5+9/XpDlQkN0aS5a5z6eWTMoBzZ/By3LH6ZHsTmIJXq2LKqpv60RTOWbFfEkXPqOXqRrsbGqU2DRxLtX7FUiH7beUzzVuzQsTOXtHLzAc1fsVPli+V29GnZd5pmLt2uPYfPaefBM+r4wQKF5MiickWDH9RmpVkuDQirV69Wp06d9Ouvv2rZsmWKi4tTvXr1FBMT48qy0owbcfHavueYalYMdbS5ubkprGKoft9xKNFlNu04pJoVijm11a5cXL/vOOy4b7fb9fqgqerSpo6KF8p1X2pH2nEjLl5/7DmmsNv3swqhTvvNP/2+47DCKoQ6tdWuXMzYL9dv3a/QJ/upYsth6vXBbEVG8X//YZUxg7vKFc2lVVsOOtosy9LqLQdVoURIosts2nlM5Yrm0qP/Hwjy5cqqJyoV0bLf9t1xPX4+XpKki9HXUrD69MmlcxCWLFnidH/KlCkKCgrSli1bVKNGDRdVlXZcuHRFCQl2BQb4OrUHBvhp3+EziS5z9kK0ArPd3t9XZy9EO+5/8s0yZXB302vP1UzxmpH2XLgUo4QEu4IC/JzagwJ8te/Iv+xnxn7pq7MX/j4lUadyCTWsWU75grPp0IlzenfcIrXqPk5LJ/WSuztnPx822fwzKYO7u85dvOLUfu7iFRXJmz3RZeat2KEA/0xaPKa9bDabMmZw19f/+12jZqxNtL/NZtOITk/q1x1HtPvw2RTfhvQmVU1SjIqKkiQFBAQk+nhsbKxiY2Md96OjoxPth/9u++6jmjBrlVZNe0s2m83V5SAda16vvOPfJQoHq2Th3CrffIjWbd1nHH0AElOtbH71bF1dvcf8qC27j6tA7gC936mBercJ00fTVhv9P+r2tIoXCFKDrl+7oNq0J9XEdLvdru7du6tatWoqVapUon1GjBghf39/xy0kJPHDTg+LbFkyy93dzZgodi4yWkHZ/BJdJiibn85duL3/ZUf/jdsO6NzFKyrdaKCyV+6q7JW76tipSL0z5juVaTzw/mwIUrVsWXzk7u6ms5HOgfxs5GXjqMItQdn8EtkvLyvotqNX/5Q/d3Zly5JZh46du/eikeZciLqq+IQEBWbN7NQemDWzzkZeSXSZ/u1qa86yP/XtT1u169BZ/bhuj4Z9tVw9Xnjc+IAzsutTql+5qBr1nKKT5/lwmRSpJiB06tRJO3fu1KxZs+7Yp1+/foqKinLcjh079gArTH08MmZQuWIhWv373xM77Xa71vy+VxVKF0h0mYqlCzj1l6SVv+1RhdL5JUnPPlVB62b005ppfR23XIH+6tKmruaP7XTftgWpl0fGDCpbLERrft/raPt7P8uf6DIVSufXms17ndpWbYq4434pSSfOXFRkVIxyZOeqmYdRXHyCtu89pbBHCzrabDabajxaQL/vSvy13tsro+x2y6ktwW7//2X/bhvZ9Sk9/XhxNe41RUdPX0rx2tOrVHGKoXPnzlq0aJHWrFmjPHny3LGfp6enPD09H2BlqV/HF2qr45Bv9UjxvHq0ZH59MXOlYq7FqnWjypKk1wdNVa5Afw3q3ESS9NpzNdXwtU/02bTlqvd4SX338xZt331Un7z9vCQpIEtmBWRxTvAZMrgrRzY/Fcmf48FuHFKNjs/XUqeh01SueF49WiKfJsxapavXY/VCw5v72RuDpypXYBYN7NRYkvTaszXV6PUx+nz6cj1RraQWLNuq7buPanS/5yRJV67G6sNJi9WwVlnlyOanQyfOa8in36tgnuyqXbnYHetA+jZu7gaN69tM2yJOaOueE3rjmSry8fLQ9CXbJElf9G2mU+cva+ikXyRJSzZGqGOLKvpz/ylt3n1cBXMH6O12tbVk415HcPio29NqUae0Xnhnpq5cvaGg/z9CER1zXddvxLtmQ9MIlwYEy7LUpUsXLViwQKtWrVKBAnf+dIHENa9XXucvXdHwCT/q7IXLKl00t+aN7eQ4ZXD8dKTc/hGlK5UtqInvttV7XyzSsHE/qGBIoKZ99KpKFOaSH9xZsydu7mfvf3lzPytVNLfmfNLRsZ+dOHNRbm5/72cVyxTUl8Pa6r3xi/TuF4tUMCRQ3458RcUL3dzP3N1s+mv/Cc366TdFXb6mnIH+qlWxmPq99rQ8Pbg+/WG1YNVfyp7FR2+3q62grJm148BptXjrW527ePPqljxB/k5HDD76do0sS+rfvrZyZffThUsxWrJxr4Z9tdzR5+UmFSVJP37S3mldHT9YoJlLt9//jUrDbJZlWXfvdn907NhRM2bM0Pfff6/Q0L8nJfn7+8vb2/uuy0dHR8vf319nLkTJzy/xc6FASrj9MCZwP2SrO9jVJSCds+JjFbvxA0VF3f1906VzEL744gtFRUWpZs2aypUrl+M2e/ZsV5YFAMBDz+WnGAAAQOqTaq5iAAAAqQcBAQAAGAgIAADAQEAAAAAGAgIAADAQEAAAgIGAAAAADAQEAABgICAAAAADAQEAABgICAAAwEBAAAAABgICAAAwEBAAAICBgAAAAAwEBAAAYCAgAAAAAwEBAAAYCAgAAMBAQAAAAAYCAgAAMBAQAACAgYAAAAAMBAQAAGAgIAAAAAMBAQAAGAgIAADAQEAAAAAGAgIAADAQEAAAgIGAAAAADAQEAABgICAAAAADAQEAABgICAAAwEBAAAAABgICAAAwEBAAAICBgAAAAAwEBAAAYCAgAAAAAwEBAAAYCAgAAMBAQAAAAAYCAgAAMBAQAACAgYAAAAAMBAQAAGAgIAAAAAMBAQAAGAgIAADAQEAAAAAGAgIAADAQEAAAgIGAAAAADAQEAABgICAAAAADAQEAABgICAAAwEBAAAAABgICAAAwEBAAAICBgAAAAAwEBAAAYCAgAAAAAwEBAAAYCAgAAMBAQAAAAAYCAgAAMGRwdQH3wrIsSdLl6GgXV4L0zm63XF0CHgJWfKyrS0A6d2sfu/X++W/SdEC4fPmyJKlwgRAXVwIAQNpx+fJl+fv7/2sfm5WUGJFK2e12nTx5Ur6+vrLZbK4uJ02Ijo5WSEiIjh07Jj8/P1eXg3SK/QwPAvtZ8lmWpcuXLys4OFhubv8+yyBNH0Fwc3NTnjx5XF1GmuTn58d/KNx37Gd4ENjPkuduRw5uYZIiAAAwEBAAAICBgPCQ8fT01KBBg+Tp6enqUpCOsZ/hQWA/u7/S9CRFAABwf3AEAQAAGAgIAADAQEAAAAAGAgIAADAQEB4yn3/+ufLnzy8vLy9VqlRJmzZtcnVJSEfWrFmjRo0aKTg4WDabTQsXLnR1SUiHRowYoQoVKsjX11dBQUFq2rSpIiIiXF1WukNAeIjMnj1bPXv21KBBg7R161aVLVtW9evX19mzZ11dGtKJmJgYlS1bVp9//rmrS0E6tnr1anXq1Em//vqrli1bpri4ONWrV08xMTGuLi1d4TLHh0ilSpVUoUIFffbZZ5Ju/pZFSEiIunTpor59+7q4OqQ3NptNCxYsUNOmTV1dCtK5c+fOKSgoSKtXr1aNGjVcXU66wRGEh8SNGze0ZcsW1a1b19Hm5uamunXrauPGjS6sDADuTVRUlCQpICDAxZWkLwSEh8T58+eVkJCgHDlyOLXnyJFDp0+fdlFVAHBv7Ha7unfvrmrVqqlUqVKuLiddSdO/5ggAeLh16tRJO3fu1Lp161xdSrpDQHhIZM+eXe7u7jpz5oxT+5kzZ5QzZ04XVQUA/13nzp21aNEirVmzRnny5HF1OekOpxgeEh4eHipfvryWL1/uaLPb7Vq+fLmqVKniwsoAIHksy1Lnzp21YMECrVixQgUKFHB1SekSRxAeIj179lR4eLgee+wxVaxYUZ988oliYmLUrl07V5eGdOLKlSvav3+/4/6hQ4e0fft2BQQEKG/evC6sDOlJp06dNGPGDH3//ffy9fV1zKPy9/eXt7e3i6tLP7jM8SHz2Wef6cMPP9Tp06dVrlw5jR07VpUqVXJ1WUgnVq1apVq1ahnt4eHhmjJlyoMvCOmSzWZLtH3y5Mlq27btgy0mHSMgAAAAA3MQAACAgYAAAAAMBAQAAGAgIAAAAAMBAQAAGAgIAADAQEAAAAAGAgIAADAQEICHVNu2bdW0aVPH/Zo1a6p79+4PvI5Vq1bJZrPp0qVLd+xjs9m0cOHCJI85ePBglStX7p7qOnz4sGw2m7Zv335P4wBpFQEBSEXatm0rm80mm80mDw8PFS5cWEOHDlV8fPx9X/d3332nYcOGJalvUt7UAaRt/FgTkMo8+eSTmjx5smJjY/XTTz+pU6dOypgxo/r162f0vXHjhjw8PFJkvQEBASkyDoD0gSMIQCrj6empnDlzKl++fHrjjTdUt25d/e9//5P092mB9957T8HBwQoNDZUkHTt2TK1atVKWLFkUEBCgJk2a6PDhw44xExIS1LNnT2XJkkXZsmXTm2++qdt/huX2UwyxsbF66623FBISIk9PTxUuXFhfffWVDh8+7PhBpqxZs8pmszl+IMdut2vEiBEqUKCAvL29VbZsWc2bN89pPT/99JOKFi0qb29v1apVy6nOpHrrrbdUtGhRZcqUSQULFtSAAQMUFxdn9JswYYJCQkKUKVMmtWrVSlFRUU6PT5o0ScWLF5eXl5eKFSumcePGJbsWIL0iIACpnLe3t27cuOG4v3z5ckVERGjZsmVatGiR4uLiVL9+ffn6+mrt2rVav369MmfOrCeffNKx3Mcff6wpU6bo66+/1rp16xQZGakFCxb863pfeuklzZw5U2PHjtXu3bs1YcIEZc6cWSEhIZo/f74kKSIiQqdOndKYMWMkSSNGjNDUqVM1fvx4/fXXX+rRo4fatGmj1atXS7oZZJo3b65GjRpp+/bt6tChg/r27Zvs58TX11dTpkzRrl27NGbMGE2cOFGjR4926rN//37NmTNHP/zwg5YsWaJt27apY8eOjsenT5+ugQMH6r333tPu3bs1fPhwDRgwQN98802y6wHSJQtAqhEeHm41adLEsizLstvt1rJlyyxPT0+rd+/ejsdz5MhhxcbGOpb59ttvrdDQUMtutzvaYmNjLW9vb2vp0qWWZVlWrly5rJEjRzoej4uLs/LkyeNYl2VZVlhYmNWtWzfLsiwrIiLCkmQtW7Ys0TpXrlxpSbIuXrzoaLt+/bqVKVMma8OGDU59X375Zev555+3LMuy+vXrZ5UoUcLp8bfeessY63aSrAULFtzx8Q8//NAqX7684/6gQYMsd3d36/jx4462xYsXW25ubtapU6csy7KsQoUKWTNmzHAaZ9iwYVaVKlUsy7KsQ4cOWZKsbdu23XG9QHrGHAQglVm0aJEyZ86suLg42e12vfDCCxo8eLDj8dKlSzvNO/jjjz+0f/9++fr6Oo1z/fp1HThwQFFRUTp16pQqVarkeCxDhgx67LHHjNMMt2zfvl3u7u4KCwtLct379+/X1atX9cQTTzi137hxQ4888ogkaffu3U51SFKVKlWSvI5bZs+erbFjx+rAgQO6cuWK4uPj5efn59Qnb968yp07t9N67Ha7IiIi5OvrqwMHDujll1/WK6+84ugTHx8vf3//ZNcDpEcEBCCVqVWrlr744gt5eHgoODhYGTI4/zf18fFxun/lyhWVL19e06dPN8YKDAz8TzV4e3sne5krV65Ikn788UenN2bp5ryKlLJx40a1bt1aQ4YMUf369eXv769Zs2bp448/TnatEydONAKLu7t7itUKpGUEBCCV8fHxUeHChZPc/9FHH9Xs2bMVFBRkfIq+JVeuXPrtt99Uo0YNSTc/KW/ZskWPPvpoov1Lly4tu92u1atXq27dusbjt45gJCQkONpKlCghT09PHT169I5HHooXL+6YcHnLr7/+eveN/IcNGzYoX7586t+/v6PtyJEjRr+jR4/q5MmTCg4OdqzHzc1NoaGhypEjh4KDg3Xw4EG1bt06WesHHhZMUgTSuNatWyt79uxq0qSJ1q5dq0OHDmnVqlXq2rWrjh8/Lknq1q2b3n//fS1cuFB79uxRx44d//U7DPLnz6/w8HC1b99eCxcudIw5Z84cSVK+fPlks9m0aNEinTt3TleuXJGvr6969+6tHj166JtvvtGBAwe0detWffrpp46Jf6+//rr27dunPn36KCIiQjNmzNCUKVOStb1FihTR0aNHNWvWLB04cEBjx45NdMKll5eXwsPD9ccff2jt2rXq2rWrWrVqpZw5c0qShgwZohEjRmjs2LHau3evduzYocmTJ2vUqFHJqgdIrwgIQBqXKVMmrVmzRnnz5lXz5s1VvHhxvfzyy7p+/brjiEKvXr304osvKjw8XFWqVJGvr6+aNWv2r+N+8cUXatGihTp27KhixYrplVdeUUxMjCQpd+7cGjJkiPr27ascOXKoc+fOkqRhw4ZpwIABGjFihIoXL64nn3xSP/74owoUKCDp5ryA+fPna+HChSpbtqzGjx+v4cOHJ2t7GzdurB49eqhz584qV66cNmzYoAEDBhj9ChcurObNm+upp55SvXr1VKZMGafLGDt06KBJkyZp8uTJKl26tMLCwjRlyhRHrcDDzmbdaZYSAAB4aHEEAQAAGAgIAADAQEAAAAAGAgIAADAQEAAAgIGAAAAADAQEAABgICAAAAADAQEAABgICAAAwEBAAAAAhv8DRGCW1jz4EegAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_preds = np.argmax(preds_output.predictions, axis=1)\n",
    "#labels = training_data_encoded[\"train\"].features[\"label\"].names\n",
    "labels = [0,1,2]\n",
    "y_valid = training_data_encoded[\"validation\"][\"label\"]\n",
    "\n",
    "plot_confusion_matrix(y_preds, y_valid, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Loss on Train/Validation Datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy \n",
    "def forward_pass_with_label(batch):\n",
    "    # Place all input tensors on the same device as the model \n",
    "    inputs = {k:v.to(device) for k,v in batch.items()\n",
    "    if k in tokenizer.model_input_names}\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        output = model(**inputs)\n",
    "        pred_label = torch.argmax(output.logits, axis=-1)\n",
    "        #class_weight = torch.FloatTensor([1, 1.25]).to(device)\n",
    "\n",
    "        loss = cross_entropy(output.logits, batch[\"label\"].to(device), reduction=\"none\")\n",
    "    # Place outputs on CPU for compatibility with other dataset columns \n",
    "    return {\"loss\": loss.cpu().numpy(),\n",
    "    \"predicted_label\": pred_label.cpu().numpy()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert our dataset back to PyTorch tensors\n",
    "training_data_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "# Compute loss values\n",
    "#test_data_encoded[\"test\"] = test_data_encoded[\"test\"].map(forward_pass_with_label, batched=True, batch_size=16)\n",
    "training_data_encoded[\"train\"] = training_data_encoded[\"train\"].map(forward_pass_with_label, batched=True, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>খোদার কসম করে বলছি আমি নিজেও আওয়ামিলীগ করি, ক...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.546422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>নাহিদের বাবা ঠিকই জানেন এদেশে বিচার হবে না তদন...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.381577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>বড় আফসোস ভারতের বোনেরা হিজাব রক্ষার জন্য লড়া...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.306884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>সকল মুসলিম ভাই ভাই তাই কোন দোষ নাই</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.151897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>এমন সুন্দর কোমল, মোলায়েম সাক্ষাৎকার কখনো দেখে...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.035587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>হিন্দু জংগি সংঘটন মোদি সরকার হটাও। হিন্দু সন্ত...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>ইকবালের বেলায় পরিবার ও দায় নেবে না আর ওর জাত...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>ধর্মের ব্যাপারে নিরপহ্ম মানেই জাহান্নামি! ভালো...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>ষড়যন্ত্রকারীরা কত শক্তিশালী! অঘটন ঘটানোর জন্য...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>এটা কি পুলিশরা দেখি ব্যবসায়ীদের দলে থেকে শিক্...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  \\\n",
       "2080  খোদার কসম করে বলছি আমি নিজেও আওয়ামিলীগ করি, ক...      1   \n",
       "425   নাহিদের বাবা ঠিকই জানেন এদেশে বিচার হবে না তদন...      0   \n",
       "689   বড় আফসোস ভারতের বোনেরা হিজাব রক্ষার জন্য লড়া...      1   \n",
       "969                  সকল মুসলিম ভাই ভাই তাই কোন দোষ নাই      1   \n",
       "1837  এমন সুন্দর কোমল, মোলায়েম সাক্ষাৎকার কখনো দেখে...      1   \n",
       "...                                                 ...    ...   \n",
       "2558  হিন্দু জংগি সংঘটন মোদি সরকার হটাও। হিন্দু সন্ত...      1   \n",
       "1088  ইকবালের বেলায় পরিবার ও দায় নেবে না আর ওর জাত...      0   \n",
       "680   ধর্মের ব্যাপারে নিরপহ্ম মানেই জাহান্নামি! ভালো...      1   \n",
       "379   ষড়যন্ত্রকারীরা কত শক্তিশালী! অঘটন ঘটানোর জন্য...      0   \n",
       "684   এটা কি পুলিশরা দেখি ব্যবসায়ীদের দলে থেকে শিক্...      0   \n",
       "\n",
       "      predicted_label      loss  \n",
       "2080                0  6.546422  \n",
       "425                 1  6.381577  \n",
       "689                 0  6.306884  \n",
       "969                 0  6.151897  \n",
       "1837                0  6.035587  \n",
       "...               ...       ...  \n",
       "2558                1  0.014612  \n",
       "1088                0  0.013778  \n",
       "680                 1  0.013637  \n",
       "379                 0  0.013260  \n",
       "684                 0  0.013068  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_encoded.set_format(\"pandas\")\n",
    "cols = [\"text\", \"label\", \"predicted_label\", \"loss\"] \n",
    "df_train_loss = training_data_encoded[\"train\"][:][cols]\n",
    "#df_test[\"label\"] = df_test[\"label\"].apply(label_int2str) \n",
    "#df_test[\"predicted_label\"] = (df_test[\"predicted_label\"].apply(label_int2str))\n",
    "df_train_loss.sort_values(\"loss\", ascending=False).head(500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_loss.sort_values(\"loss\", ascending=False).head(200).to_csv(\"ErrorAnalysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Text Classification Env",
   "language": "python",
   "name": "textclassification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
